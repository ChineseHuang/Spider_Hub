# Lagou Spider
拉勾网爬虫，可爬取拉勾网的招聘信息，运行`Analysis.py`可对爬取的数据进行分析并生成报告。  
## 需要额外安装的库
BeautifulSoup  
`pip3 install bs4`  
numpy  
`pip3 install numpy`  
## 各模块功能  
### 爬虫模块  

* `dbAPI.py`:  数据库接口模块，在此定义数据的存储方式。

* `settings.py`:  用于设置起始页面，休眠时间以及是否打开多线程（经过多次实验，实际使用时尽量不要开多线程）。

* `spider.py`:  定义了爬虫的爬取规则和逻辑。

* `main.py`:  程序的入口和多线程的抓取的实现。  

### 分析模块。
* `Analysis.py`:  分析模块的主程序，定义了全部的分析逻辑。用于数据分析和生成报告。

## 运行方法
* 先在`settings.py`设置好起始页面和参数。然后运行`main.py`。   
* 在数据库中数据量足够大的时候，可以运行`Analysis.py`，对数据库中的数据进行分析，从而获得目前求职市场的基本情况。


## 原理  
### 爬虫模块  
* 主函数从`settings.py`模块提取出起始URL列表（每个URL代表着一个求职方向，如Java, PHP, Node.js等）。  
* 每个URL都被包装成1个`spider`对象，代表1个线程。   
* 线程启动后，将URL信息传入`spider.py`模块，`spider.py`模块内的函数对页面进行解析，和数据提取，然后存入以求职方向命名的数据库表中。  
* 由于一个网页能显示的公司数十有限的，所以，该网页中一定有名为“下一页”的按钮，所以，`getInfo`函数还会从所有的内链中筛选出代表着“下一页”的链接，并进入其中抓取和储存，直到把所有与该方向有关的求职信息抓完为止，所有线程都完成后，程序停止。   

### 分析模块  
* 程序将整个数据库读出，放入一个列表中，然后从列表中单独提取出薪资和地区分布。
* 薪资因为是字符串类型，并且还带有字母和汉字，`dealSalary`函数对薪资进行再加工剔除无意义的字符，并将其转化为int型，`salaryAns`函数对所有的薪资进行整合，求出最低和最高薪资，和平均薪资并输出。
* 地域分布这一字段的内容也是比较复杂，有的是"城市·区"的形式，有的是"城市"的形式，所以`getPosition`函数对其进行解析，并提取出城市名字，然后`positionAns`函数对所有工作单位所在的城市进行统计，把城市按照拥有的招聘单位的数量来从大到小排列，并输出前五名。


*********  
### 部分运行结果
![image](/example.png)  
![image](/example1.png)   


